{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbS5RPrEIaCy/rZJXQdA9R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSDK_7Dj3YH9","executionInfo":{"status":"ok","timestamp":1765363557453,"user_tz":-300,"elapsed":19050,"user":{"displayName":"Mohammad Khawar Zia","userId":"09590528074534920118"}},"outputId":"74ef6caa-8c1e-48a4-dfe9-8e0a4cfdfdeb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/Colab Notebooks/housing_fall2025\n"]}]},{"cell_type":"code","source":["!pip install optuna xgboost lightgbm \"mlflow<3\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"quIhilm65orD","executionInfo":{"status":"ok","timestamp":1765364125436,"user_tz":-300,"elapsed":15141,"user":{"displayName":"Mohammad Khawar Zia","userId":"09590528074534920118"}},"outputId":"88a456ac-cfe6-4b88-f33f-5e9f7f32902b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n","Collecting mlflow<3\n","  Downloading mlflow-2.22.4-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n","Collecting mlflow-skinny==2.22.4 (from mlflow<3)\n","  Downloading mlflow_skinny-2.22.4-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow<3) (3.1.2)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.12/dist-packages (from mlflow<3) (3.1.6)\n","Collecting docker<8,>=4.0.0 (from mlflow<3)\n","  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting graphene<4 (from mlflow<3)\n","  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n","Collecting gunicorn<24 (from mlflow<3)\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.12/dist-packages (from mlflow<3) (3.10)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow<3) (3.10.0)\n","Requirement already satisfied: pandas!=2.3.0,<3 in /usr/local/lib/python3.12/dist-packages (from mlflow<3) (2.2.2)\n","Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow<3) (18.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow<3) (1.6.1)\n","Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.22.4->mlflow<3)\n","  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.3.1)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.1.2)\n","Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.4->mlflow<3)\n","  Downloading databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.118.3)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.1.45)\n","Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.7.0)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.37.0)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.37.0)\n","Collecting packaging>=20.0 (from optuna)\n","  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (5.29.5)\n","Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.12.3)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.32.4)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.5.4)\n","Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (4.15.0)\n","Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.38.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow<3) (2.5.0)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3) (1.9.0)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3) (2.2.0)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3) (3.0.3)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3) (3.1.4)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow<3)\n","  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow<3)\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow<3) (2.9.0.post0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3) (4.61.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3) (3.2.5)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.3.0,<3->mlflow<3) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.3.0,<3->mlflow<3) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow<3) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow<3) (3.6.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (2.43.0)\n","Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (0.48.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (4.0.12)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.4->mlflow<3) (3.23.0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.4->mlflow<3) (0.58b0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (0.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow<3) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (3.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (2025.11.12)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==2.22.4->mlflow<3) (0.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (5.0.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (4.9.1)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (4.12.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.6.1)\n","Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow-2.22.4-py3-none-any.whl (29.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_skinny-2.22.4-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n","Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n","Downloading databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Installing collected packages: packaging, graphql-core, colorlog, cachetools, gunicorn, graphql-relay, docker, optuna, graphene, databricks-sdk, mlflow-skinny, mlflow\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 25.0\n","    Uninstalling packaging-25.0:\n","      Successfully uninstalled packaging-25.0\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 6.2.2\n","    Uninstalling cachetools-6.2.2:\n","      Successfully uninstalled cachetools-6.2.2\n","Successfully installed cachetools-5.5.2 colorlog-6.10.1 databricks-sdk-0.73.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.22.4 mlflow-skinny-2.22.4 optuna-4.6.0 packaging-24.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cachetools","packaging"]},"id":"646f92173a2a4e9983e17023b327dd0c"}},"metadata":{}}]},{"cell_type":"code","source":["base_folder = \"/content/gdrive/MyDrive/Colab Notebooks/housing_fall2025\"\n","%cd \"{base_folder}\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRFqzWx-55CJ","executionInfo":{"status":"ok","timestamp":1765364176936,"user_tz":-300,"elapsed":82,"user":{"displayName":"Mohammad Khawar Zia","userId":"09590528074534920118"}},"outputId":"eb7be809-34df-420d-c2b7-2722fddb53bb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/housing_fall2025\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"m1pqkWQ53TFh","executionInfo":{"status":"ok","timestamp":1765364179989,"user_tz":-300,"elapsed":204,"user":{"displayName":"Mohammad Khawar Zia","userId":"09590528074534920118"}},"outputId":"b7907949-6e25-4a19-89a2-b2d7c8bd317e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   block_id  longitude  latitude  housing_median_age  total_rooms  \\\n","0         0    -122.23     37.88                41.0          880   \n","1         1    -122.22     37.86                21.0         7099   \n","2         2    -122.24     37.85                52.0         1467   \n","3         3    -122.25     37.85                52.0         1274   \n","4         4    -122.25     37.85                52.0         1627   \n","\n","   total_bedrooms  population  households  median_income  median_house_value  \\\n","0           129.0         322         126         8.3252            452600.0   \n","1          1106.0        2401        1138         8.3014            358500.0   \n","2           190.0         496         177         7.2574            352100.0   \n","3           235.0         558         219         5.6431            341300.0   \n","4           280.0         565         259         3.8462            342200.0   \n","\n","  ocean_proximity  \n","0        NEAR BAY  \n","1        NEAR BAY  \n","2        NEAR BAY  \n","3        NEAR BAY  \n","4        NEAR BAY  "],"text/html":["\n","  <div id=\"df-8b0e0e7d-c701-4d49-8997-8957b42f6d72\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>block_id</th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","      <th>ocean_proximity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-122.23</td>\n","      <td>37.88</td>\n","      <td>41.0</td>\n","      <td>880</td>\n","      <td>129.0</td>\n","      <td>322</td>\n","      <td>126</td>\n","      <td>8.3252</td>\n","      <td>452600.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>-122.22</td>\n","      <td>37.86</td>\n","      <td>21.0</td>\n","      <td>7099</td>\n","      <td>1106.0</td>\n","      <td>2401</td>\n","      <td>1138</td>\n","      <td>8.3014</td>\n","      <td>358500.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-122.24</td>\n","      <td>37.85</td>\n","      <td>52.0</td>\n","      <td>1467</td>\n","      <td>190.0</td>\n","      <td>496</td>\n","      <td>177</td>\n","      <td>7.2574</td>\n","      <td>352100.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>-122.25</td>\n","      <td>37.85</td>\n","      <td>52.0</td>\n","      <td>1274</td>\n","      <td>235.0</td>\n","      <td>558</td>\n","      <td>219</td>\n","      <td>5.6431</td>\n","      <td>341300.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-122.25</td>\n","      <td>37.85</td>\n","      <td>52.0</td>\n","      <td>1627</td>\n","      <td>280.0</td>\n","      <td>565</td>\n","      <td>259</td>\n","      <td>3.8462</td>\n","      <td>342200.0</td>\n","      <td>NEAR BAY</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b0e0e7d-c701-4d49-8997-8957b42f6d72')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8b0e0e7d-c701-4d49-8997-8957b42f6d72 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8b0e0e7d-c701-4d49-8997-8957b42f6d72');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-d692b4a2-4ad8-4738-a40a-ca4bb698e916\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d692b4a2-4ad8-4738-a40a-ca4bb698e916')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-d692b4a2-4ad8-4738-a40a-ca4bb698e916 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"housing","summary":"{\n  \"name\": \"housing\",\n  \"rows\": 20640,\n  \"fields\": [\n    {\n      \"column\": \"block_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5958,\n        \"min\": 0,\n        \"max\": 20639,\n        \"num_unique_values\": 20640,\n        \"samples\": [\n          20046,\n          3024,\n          15663\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0035317235025802,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 844,\n        \"samples\": [\n          -123.39,\n          -122.08,\n          -116.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.135952397457107,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          36.16,\n          36.28,\n          32.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.585557612111748,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          35.0,\n          25.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2181,\n        \"min\": 2,\n        \"max\": 39320,\n        \"num_unique_values\": 5926,\n        \"samples\": [\n          913,\n          1759,\n          6434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.38507007403194,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1923,\n        \"samples\": [\n          1296.0,\n          3493.0,\n          2035.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1132,\n        \"min\": 3,\n        \"max\": 35682,\n        \"num_unique_values\": 3888,\n        \"samples\": [\n          3622,\n          3232,\n          2291\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382,\n        \"min\": 1,\n        \"max\": 6082,\n        \"num_unique_values\": 1815,\n        \"samples\": [\n          745,\n          1248,\n          1166\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8998217179452694,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 12928,\n        \"samples\": [\n          2.5211,\n          4.2454,\n          2.1681\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115395.61587441301,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 3842,\n        \"samples\": [\n          400700.0,\n          264900.0,\n          119100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<1H OCEAN\",\n          \"ISLAND\",\n          \"INLAND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}],"source":["import sqlite3\n","import pandas as pd\n","conn = sqlite3.connect(f\"{base_folder}/data/housing.db\")\n","housing = pd.read_sql_query(\n","    \"\"\"\n","    SELECT\n","        b.block_id,\n","        b.longitude,\n","        b.latitude,\n","        s.housing_median_age,\n","        s.total_rooms,\n","        s.total_bedrooms,\n","        s.population,\n","        s.households,\n","        s.median_income,\n","        s.median_house_value,\n","        op.name AS ocean_proximity\n","    FROM block AS b\n","    JOIN block_housing_stats AS s\n","        ON s.block_id = b.block_id\n","    JOIN ocean_proximity AS op\n","        ON op.ocean_proximity_id = b.ocean_proximity_id\n","    ORDER BY b.block_id\n","    \"\"\",\n","    conn,\n",")\n","conn.close()\n","\n","housing.head()"]},{"cell_type":"code","source":["# =============================================================================\n","# FULL PIPELINE:\n","# - Build preprocessing\n","# - Stratified train/test split\n","# - Train & log 4 models WITHOUT PCA (Ridge, HGB, XGBoost, LightGBM)\n","# - Train & log 4 models WITH PCA (preprocessing + PCA(0.95) + model)\n","# - Pick GLOBAL best among 8 models by Test MAE\n","# - Save, load, and compare the global best model\n","# =============================================================================\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","from dotenv import load_dotenv\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.cluster import KMeans\n","from sklearn.compose import ColumnTransformer, make_column_selector\n","from sklearn.decomposition import PCA\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics.pairwise import rbf_kernel\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n","from sklearn.linear_model import Ridge\n","from sklearn.ensemble import HistGradientBoostingRegressor\n","\n","import mlflow\n","from mlflow.models import infer_signature\n","import joblib\n","\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","\n","# -----------------------------------------------------------------------------\n","# ASSUMPTION: housing DataFrame is already loaded.\n","# It must contain:\n","#   - median_income, median_house_value, block_id\n","#   - latitude, longitude\n","#   - total_bedrooms, total_rooms, households, population, median_income\n","#   - any categorical columns (object dtype)\n","#\n","# Example:\n","# housing = pd.read_csv(\"housing.csv\")\n","# -----------------------------------------------------------------------------\n","\n","\n","# =============================================================================\n","# STEP 1: Build Full ML Preprocessing Pipeline\n","# =============================================================================\n","\n","class ClusterSimilarity(BaseEstimator, TransformerMixin):\n","    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n","        self.n_clusters = n_clusters\n","        self.gamma = gamma\n","        self.random_state = random_state\n","\n","    def fit(self, X, y=None, sample_weight=None):\n","        self.kmeans_ = KMeans(\n","            self.n_clusters,\n","            n_init=10,\n","            random_state=self.random_state\n","        )\n","        self.kmeans_.fit(X, sample_weight=sample_weight)\n","        return self\n","\n","    def transform(self, X):\n","        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n","\n","    def fit_transform(self, X, y=None, sample_weight=None):\n","        self.fit(X, y, sample_weight)\n","        return self.transform(X)\n","\n","    def get_feature_names_out(self, names=None):\n","        return [f\"Cluster {i} similarity\" for i in range(self.n_clusters)]\n","\n","\n","def column_ratio(X):\n","    return X[:, [0]] / X[:, [1]]\n","\n","def ratio_name(function_transformer, feature_names_in):\n","    return [\"ratio\"]\n","\n","def ratio_pipeline():\n","    return make_pipeline(\n","        SimpleImputer(strategy=\"median\"),\n","        FunctionTransformer(column_ratio, feature_names_out=ratio_name),\n","        StandardScaler(),\n","    )\n","\n","log_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"median\"),\n","    FunctionTransformer(np.log, feature_names_out=\"one-to-one\"),\n","    StandardScaler(),\n",")\n","\n","cluster_simil = ClusterSimilarity(n_clusters=10, gamma=1.0, random_state=42)\n","\n","cat_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"most_frequent\"),\n","    OneHotEncoder(handle_unknown=\"ignore\"),\n",")\n","\n","default_num_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"median\"),\n","    StandardScaler(),\n",")\n","\n","preprocessing = ColumnTransformer(\n","    [\n","        (\"bedrooms\",        ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]),\n","        (\"rooms_per_house\", ratio_pipeline(), [\"total_rooms\", \"households\"]),\n","        (\"people_per_house\",ratio_pipeline(), [\"population\", \"households\"]),\n","        (\"log\",             log_pipeline,\n","            [\"total_bedrooms\", \"total_rooms\", \"population\",\n","             \"households\", \"median_income\"]),\n","        (\"geo\",             cluster_simil, [\"latitude\", \"longitude\"]),\n","        (\"cat\",             cat_pipeline, make_column_selector(dtype_include=object)),\n","    ],\n","    remainder=default_num_pipeline,\n",")\n","\n","print(\"✓ STEP 1: Preprocessing pipeline created.\")\n","\n","\n","# =============================================================================\n","# STEP 2: Split Data into Stratified Train and Test Sets\n","# =============================================================================\n","\n","housing[\"income_cat\"] = pd.cut(\n","    housing[\"median_income\"],\n","    bins=[0, 1.5, 3.0, 4.5, 6, np.inf],\n","    labels=[1, 2, 3, 4, 5],\n",")\n","\n","train_set, test_set = train_test_split(\n","    housing,\n","    test_size=0.20,\n","    stratify=housing[\"income_cat\"],\n","    random_state=42,\n",")\n","\n","# Drop income_cat after stratification\n","for df in (train_set, test_set):\n","    df.drop(\"income_cat\", axis=1, inplace=True)\n","\n","X_train = train_set.drop([\"block_id\", \"median_house_value\"], axis=1).copy()\n","y_train = train_set[\"median_house_value\"].copy()\n","\n","X_test = test_set.drop([\"block_id\", \"median_house_value\"], axis=1).copy()\n","y_test = test_set[\"median_house_value\"].copy()\n","\n","print(f\"✓ STEP 2: Stratified split done. Train size: {len(X_train)}, Test size: {len(X_test)}\")\n","\n","\n","# =============================================================================\n","# STEP 3: Define 4 Model Pipelines (WITHOUT PCA)\n","# =============================================================================\n","\n","ridge_pipeline = make_pipeline(\n","    preprocessing,\n","    Ridge()\n",")\n","\n","hgb_pipeline = make_pipeline(\n","    preprocessing,\n","    HistGradientBoostingRegressor(random_state=42)\n",")\n","\n","xgb_pipeline = make_pipeline(\n","    preprocessing,\n","    XGBRegressor(\n","        objective=\"reg:squarederror\",\n","        random_state=42,\n","        n_estimators=300,\n","        learning_rate=0.1,\n","        max_depth=6,\n","        subsample=0.8,\n","        colsample_bytree=0.8,\n","        tree_method=\"hist\",\n","        n_jobs=-1,\n","    ),\n",")\n","\n","lgbm_pipeline = make_pipeline(\n","    preprocessing,\n","    LGBMRegressor(\n","        random_state=42,\n","        n_estimators=300,\n","        learning_rate=0.05,\n","        num_leaves=31,\n","        subsample=0.8,\n","        colsample_bytree=0.8,\n","        n_jobs=-1,\n","    ),\n",")\n","\n","models = {\n","    \"ridge\": ridge_pipeline,\n","    \"histgradientboosting\": hgb_pipeline,\n","    \"xgboost\": xgb_pipeline,\n","    \"lightgbm\": lgbm_pipeline,\n","}\n","\n","print(\"✓ STEP 3: 4 baseline model pipelines defined.\")\n","\n","\n","# =============================================================================\n","# STEP 4: Configure MLflow (e.g., Dagshub) via .env\n","# =============================================================================\n","\n","load_dotenv()  # .env should contain MLFLOW_TRACKING_URI, USERNAME, PASSWORD\n","\n","MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n","MLFLOW_TRACKING_USERNAME = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n","MLFLOW_TRACKING_PASSWORD = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n","\n","if MLFLOW_TRACKING_USERNAME:\n","    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = MLFLOW_TRACKING_USERNAME\n","if MLFLOW_TRACKING_PASSWORD:\n","    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = MLFLOW_TRACKING_PASSWORD\n","\n","mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n","mlflow.set_experiment(\"median_house_pricing_multi_model\")\n","\n","print(\"✓ STEP 4: MLflow configured.\")\n","\n","\n","# =============================================================================\n","# STEP 5: Train, Evaluate, and Log 4 Baseline Models (NO PCA)\n","# =============================================================================\n","\n","results = {}  # name -> {\"pipeline\": ..., \"test_mae\": ...}\n","\n","for name, pipeline in models.items():\n","    print(f\"\\n{'=' * 80}\")\n","    print(f\"Training baseline model: {name}\")\n","    print(f\"{'=' * 80}\")\n","\n","    # Fit\n","    pipeline.fit(X_train, y_train)\n","\n","    # Evaluate\n","    y_pred = pipeline.predict(X_test)\n","    test_mae = mean_absolute_error(y_test, y_pred)\n","    print(f\"{name} (no PCA) Test MAE: ${test_mae:,.2f}\")\n","\n","    results[name] = {\"pipeline\": pipeline, \"test_mae\": test_mae}\n","\n","    # Log to MLflow\n","    with mlflow.start_run(run_name=f\"{name}_baseline\"):\n","        mlflow.log_param(\"model_family\", name)\n","        mlflow.log_param(\"uses_pca\", False)\n","\n","        # Log estimator params\n","        est_step_name = list(pipeline.named_steps.keys())[-1]\n","        est = pipeline.named_steps[est_step_name]\n","        est_params = {f\"{est_step_name}__{k}\": v for k, v in est.get_params().items()}\n","        mlflow.log_params(est_params)\n","\n","        # Metric\n","        mlflow.log_metric(\"test_MAE\", test_mae)\n","\n","        # Signature + model\n","        signature = infer_signature(X_train, pipeline.predict(X_train))\n","        mlflow.sklearn.log_model(\n","            sk_model=pipeline,\n","            artifact_path=\"housing_model\",\n","            signature=signature,\n","            input_example=X_train,\n","            registered_model_name=f\"{name}_pipeline\",\n","        )\n","\n","print(\"\\n✓ STEP 5: All 4 baseline models trained and logged.\")\n","\n","\n","# =============================================================================\n","# STEP 6: Helper to Build an Estimator by Name (for PCA variants)\n","# =============================================================================\n","\n","def make_estimator_for_name(name: str):\n","    if name == \"ridge\":\n","        return Ridge()\n","    elif name == \"histgradientboosting\":\n","        return HistGradientBoostingRegressor(random_state=42)\n","    elif name == \"xgboost\":\n","        return XGBRegressor(\n","            objective=\"reg:squarederror\",\n","            random_state=42,\n","            n_estimators=300,\n","            learning_rate=0.1,\n","            max_depth=6,\n","            subsample=0.8,\n","            colsample_bytree=0.8,\n","            tree_method=\"hist\",\n","            n_jobs=-1,\n","        )\n","    elif name == \"lightgbm\":\n","        return LGBMRegressor(\n","            random_state=42,\n","            n_estimators=300,\n","            learning_rate=0.05,\n","            num_leaves=31,\n","            subsample=0.8,\n","            colsample_bytree=0.8,\n","            n_jobs=-1,\n","        )\n","    else:\n","        raise ValueError(f\"Unknown model name: {name}\")\n","\n","\n","# =============================================================================\n","# STEP 7: Train, Evaluate, and Log PCA Versions of ALL 4 Models\n","# =============================================================================\n","\n","pca_results = {}  # key: \"<name>_with_pca\" -> {\"pipeline\": ..., \"test_mae\": ...}\n","\n","for name in models.keys():\n","    print(\"\\n\" + \"=\" * 80)\n","    print(f\"Training PCA-augmented model: {name}\")\n","    print(\"=\" * 80)\n","\n","    est = make_estimator_for_name(name)\n","\n","    # Pipeline: preprocessing -> PCA -> estimator\n","    pca_pipeline = make_pipeline(\n","        preprocessing,\n","        PCA(n_components=0.95),\n","        est,\n","    )\n","\n","    pca_pipeline.fit(X_train, y_train)\n","    y_pred_pca = pca_pipeline.predict(X_test)\n","    test_mae_pca = mean_absolute_error(y_test, y_pred_pca)\n","\n","    model_key = f\"{name}_with_pca\"\n","    pca_results[model_key] = {\n","        \"pipeline\": pca_pipeline,\n","        \"test_mae\": test_mae_pca,\n","    }\n","\n","    print(f\"{model_key} Test MAE: ${test_mae_pca:,.2f}\")\n","\n","    # Log PCA model to MLflow\n","    with mlflow.start_run(run_name=model_key):\n","        mlflow.log_param(\"model_family\", name)\n","        mlflow.log_param(\"uses_pca\", True)\n","\n","        # Estimator params\n","        est_step_name = list(pca_pipeline.named_steps.keys())[-1]\n","        est_step = pca_pipeline.named_steps[est_step_name]\n","        est_params = {f\"{est_step_name}__{k}\": v for k, v in est_step.get_params().items()}\n","        mlflow.log_params(est_params)\n","\n","        # PCA params\n","        pca_step = pca_pipeline.named_steps[\"pca\"]\n","        mlflow.log_param(\"pca__n_components\", pca_step.n_components)\n","\n","        # Metric\n","        mlflow.log_metric(\"test_MAE\", test_mae_pca)\n","\n","        # Signature + model\n","        signature_pca = infer_signature(X_train, pca_pipeline.predict(X_train))\n","        mlflow.sklearn.log_model(\n","            sk_model=pca_pipeline,\n","            artifact_path=\"housing_model_with_pca\",\n","            signature=signature_pca,\n","            input_example=X_train,\n","            registered_model_name=f\"{name}_pipeline_with_pca\",\n","        )\n","\n","print(\"\\n✓ STEP 7: All 4 PCA models trained and logged.\")\n","\n","\n","# =============================================================================\n","# STEP 8: Choose GLOBAL Best Model (with or without PCA)\n","# =============================================================================\n","\n","# Combine baseline and PCA results\n","all_results = {}\n","all_results.update(results)      # \"ridge\", \"xgboost\", ...\n","all_results.update(pca_results)  # \"ridge_with_pca\", \"xgboost_with_pca\", ...\n","\n","global_best_name = min(all_results, key=lambda k: all_results[k][\"test_mae\"])\n","global_best_mae = all_results[global_best_name][\"test_mae\"]\n","global_best_pipeline = all_results[global_best_name][\"pipeline\"]\n","\n","uses_pca = \"with_pca\" in global_best_name\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\")\n","print(\"=\" * 80)\n","print(f\"Global best model key: {global_best_name}\")\n","print(f\"Global best Test MAE:  ${global_best_mae:,.2f}\")\n","print(f\"Uses PCA:               {uses_pca}\")\n","\n","\n","# =============================================================================\n","# STEP 9: Save, Load, and Compare the GLOBAL Best Model\n","# =============================================================================\n","\n","def save_model(model, filename=\"global_best_model.pkl\"):\n","    joblib.dump(model, filename)\n","    print(f\"✓ Model saved to {filename}\")\n","\n","def load_model(filename=\"global_best_model.pkl\"):\n","    model = joblib.load(filename)\n","    print(f\"✓ Model loaded from {filename}\")\n","    return model\n","\n","def compare_model_predictions(model_in_memory, model_loaded, X, y, n_samples=5):\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"MODEL COMPARISON: In-Memory vs Loaded from Disk\")\n","    print(\"=\" * 80)\n","\n","    preds_mem = model_in_memory.predict(X)\n","    preds_load = model_loaded.predict(X)\n","\n","    mae_mem = mean_absolute_error(y, preds_mem)\n","    mae_load = mean_absolute_error(y, preds_load)\n","\n","    print(f\"\\nTest MAE (memory): ${mae_mem:,.2f}\")\n","    print(f\"Test MAE (loaded): ${mae_load:,.2f}\")\n","    print(f\"Difference in MAE:  ${abs(mae_mem - mae_load):,.2f}\")\n","\n","    print(f\"\\n{'-' * 80}\")\n","    print(f\"Sample Predictions (first {n_samples}):\")\n","    print(f\"{'-' * 80}\")\n","    print(f\"{'Actual':<15} {'Memory Model':<15} {'Loaded Model':<15} {'Diff':<15}\")\n","    print(f\"{'-' * 80}\")\n","\n","    for i in range(min(n_samples, len(y))):\n","        actual = y.iloc[i] if hasattr(y, \"iloc\") else y[i]\n","        pm = preds_mem[i]\n","        pl = preds_load[i]\n","        diff = abs(pm - pl)\n","        print(f\"${actual:<14,.0f} ${pm:<14,.2f} ${pl:<14,.2f} ${diff:<14,.2f}\")\n","\n","    diff_all = np.abs(preds_mem - preds_load)\n","    are_identical = np.allclose(preds_mem, preds_load)\n","    max_diff = diff_all.max()\n","\n","    print(f\"\\n{'-' * 80}\")\n","    if are_identical:\n","        print(\"✓ SUCCESS: Predictions are identical (within numerical precision)\")\n","    else:\n","        print(\"✗ WARNING: Predictions differ!\")\n","    print(f\"Maximum absolute difference: {max_diff:.10f}\")\n","    print(f\"Total predictions compared: {len(preds_mem)}\")\n","    print(\"=\" * 80)\n","\n","    return {\n","        \"mae_memory\": mae_mem,\n","        \"mae_loaded\": mae_load,\n","        \"are_identical\": are_identical,\n","        \"max_difference\": max_diff,\n","    }\n","\n","\n","print(\"\\n\" + \"-\" * 80)\n","print(\"Saving and reloading GLOBAL best model...\")\n","print(\"-\" * 80)\n","\n","save_model(global_best_pipeline, filename=f\"{base_folder}/models/global_best_model.pkl\")\n","loaded_global_best = load_model(f\"{base_folder}/models/global_best_model.pkl\")\n","\n","# Remove. Just for demo purposes\n","\n","comparison = compare_model_predictions(\n","    model_in_memory=global_best_pipeline,\n","    model_loaded=loaded_global_best,\n","    X=X_test,\n","    y=y_test,\n","    n_samples=10,\n",")\n","\n","print(\"\\nDone:\")\n","print(f\"- GLOBAL best model key: {global_best_name}\")\n","print(f\"- GLOBAL best Test MAE:  ${global_best_mae:,.2f}\")\n","print(f\"- Saved & loaded global best; predictions match: {comparison['are_identical']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RTqNkkbR33iG","executionInfo":{"status":"ok","timestamp":1765364256261,"user_tz":-300,"elapsed":68761,"user":{"displayName":"Mohammad Khawar Zia","userId":"09590528074534920118"}},"outputId":"62e1be45-649a-463e-b0e5-76aae236c527"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["2025/12/10 10:56:36 INFO mlflow.tracking.fluent: Experiment with name 'median_house_pricing_multi_model' does not exist. Creating a new experiment.\n"]},{"output_type":"stream","name":"stdout","text":["✓ STEP 1: Preprocessing pipeline created.\n","✓ STEP 2: Stratified split done. Train size: 16512, Test size: 4128\n","✓ STEP 3: 4 baseline model pipelines defined.\n","✓ STEP 4: MLflow configured.\n","\n","================================================================================\n","Training baseline model: ridge\n","================================================================================\n","ridge (no PCA) Test MAE: $52,350.18\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","Successfully registered model 'ridge_pipeline'.\n","Created version '1' of model 'ridge_pipeline'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","Training baseline model: histgradientboosting\n","================================================================================\n","histgradientboosting (no PCA) Test MAE: $30,702.41\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","Successfully registered model 'histgradientboosting_pipeline'.\n","Created version '1' of model 'histgradientboosting_pipeline'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","Training baseline model: xgboost\n","================================================================================\n","xgboost (no PCA) Test MAE: $28,465.49\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","Successfully registered model 'xgboost_pipeline'.\n","Created version '1' of model 'xgboost_pipeline'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","Training baseline model: lightgbm\n","================================================================================\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001819 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4651\n","[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 23\n","[LightGBM] [Info] Start training from score 206333.518653\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["lightgbm (no PCA) Test MAE: $29,684.98\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","Successfully registered model 'lightgbm_pipeline'.\n","Created version '1' of model 'lightgbm_pipeline'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","✓ STEP 5: All 4 baseline models trained and logged.\n","\n","================================================================================\n","Training PCA-augmented model: ridge\n","================================================================================\n","ridge_with_pca Test MAE: $56,738.52\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","Successfully registered model 'ridge_pipeline_with_pca'.\n","Created version '1' of model 'ridge_pipeline_with_pca'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","Training PCA-augmented model: histgradientboosting\n","================================================================================\n","histgradientboosting_with_pca Test MAE: $37,990.38\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","Successfully registered model 'histgradientboosting_pipeline_with_pca'.\n","Created version '1' of model 'histgradientboosting_pipeline_with_pca'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","Training PCA-augmented model: xgboost\n","================================================================================\n","xgboost_with_pca Test MAE: $37,367.20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","Successfully registered model 'xgboost_pipeline_with_pca'.\n","Created version '1' of model 'xgboost_pipeline_with_pca'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","Training PCA-augmented model: lightgbm\n","================================================================================\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002270 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 9\n","[LightGBM] [Info] Start training from score 206333.518653\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["lightgbm_with_pca Test MAE: $37,631.80\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","Successfully registered model 'lightgbm_pipeline_with_pca'.\n","Created version '1' of model 'lightgbm_pipeline_with_pca'.\n"]},{"output_type":"stream","name":"stdout","text":["\n","✓ STEP 7: All 4 PCA models trained and logged.\n","\n","================================================================================\n","GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\n","================================================================================\n","Global best model key: xgboost\n","Global best Test MAE:  $28,465.49\n","Uses PCA:               False\n","\n","--------------------------------------------------------------------------------\n","Saving and reloading GLOBAL best model...\n","--------------------------------------------------------------------------------\n","✓ Model saved to /content/gdrive/MyDrive/Colab Notebooks/housing_fall2025/models/global_best_model.pkl\n","✓ Model loaded from /content/gdrive/MyDrive/Colab Notebooks/housing_fall2025/models/global_best_model.pkl\n","\n","================================================================================\n","MODEL COMPARISON: In-Memory vs Loaded from Disk\n","================================================================================\n","\n","Test MAE (memory): $28,465.49\n","Test MAE (loaded): $28,465.49\n","Difference in MAE:  $0.00\n","\n","--------------------------------------------------------------------------------\n","Sample Predictions (first 10):\n","--------------------------------------------------------------------------------\n","Actual          Memory Model    Loaded Model    Diff           \n","--------------------------------------------------------------------------------\n","$397,700        $405,637.75     $405,637.75     $0.00          \n","$202,900        $218,364.11     $218,364.11     $0.00          \n","$310,000        $373,680.06     $373,680.06     $0.00          \n","$314,300        $337,835.50     $337,835.50     $0.00          \n","$187,500        $251,801.75     $251,801.75     $0.00          \n","$141,700        $164,745.59     $164,745.59     $0.00          \n","$104,900        $120,072.11     $120,072.11     $0.00          \n","$275,100        $322,629.00     $322,629.00     $0.00          \n","$167,000        $272,697.56     $272,697.56     $0.00          \n","$457,700        $325,671.91     $325,671.91     $0.00          \n","\n","--------------------------------------------------------------------------------\n","✓ SUCCESS: Predictions are identical (within numerical precision)\n","Maximum absolute difference: 0.0000000000\n","Total predictions compared: 4128\n","================================================================================\n","\n","Done:\n","- GLOBAL best model key: xgboost\n","- GLOBAL best Test MAE:  $28,465.49\n","- Saved & loaded global best; predictions match: True\n"]}]}]}